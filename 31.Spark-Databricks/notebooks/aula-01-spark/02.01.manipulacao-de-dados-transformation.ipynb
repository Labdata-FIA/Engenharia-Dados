{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b323181-c8f1-42b6-b4ee-b20551649c0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Manipulação de Dados com DataFrames no PySpark - Transformações\n",
    "\n",
    "**Objetivo:** Esta seção demonstra como realizar operações comuns com DataFrames no PySpark e apresenta seus equivalentes em SQL.\n",
    "\n",
    "---\n",
    "\n",
    "#### Criação a partir de arquivos de um CSV\n",
    "\n",
    "- DataFrames podem ser criados lendo diretamente de arquivos. O Spark suporta múltiplos formatos de arquivos, como CSV, JSON, Parquet, ORC, Avro, entre outros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69301e55-fa61-4944-8bb3-f6f3f22671b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a3b72c7-f252-4fec-b3a0-2f159eadbbdc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "\n",
    "\n",
    "# Definindo um esquema para o DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"Month\", StringType(), True),\n",
    "    StructField(\"1958\", DoubleType(), True),\n",
    "    StructField(\"1959\", DoubleType(), True),\n",
    "    StructField(\"1960\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "# Carregando o CSV como DataFrame\n",
    "df = (\n",
    "    spark\n",
    "        .read\n",
    "        .csv(\n",
    "            \"/Volumes/workspace/default/laboratorio-spark/airtravel.csv\",\n",
    "            header=True,\n",
    "            schema=schema\n",
    "        )\n",
    "        .withColumnsRenamed(colsMap={\n",
    "            '\"1958\"': '1958', \n",
    "            '\"1959\"': '1959',\n",
    "            '\"1960\"': '1960'\n",
    "        })\n",
    ")\n",
    "df.createOrReplaceTempView(\"airtravel\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a03ed4f1-21a2-4944-9615-b5fdedfcab3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### Operações com DataFrames\n",
    "\n",
    "##### Seleção de Colunas (`select`)\n",
    "\n",
    "###### Usando `F.col`\n",
    "\n",
    "No PySpark, `F.col` é utilizado para referenciar colunas programaticamente, especialmente útil quando os nomes das colunas são dinâmicos ou utilizados em expressões.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9215561f-c767-43a3-9821-2bf9b89972ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Selecionar colunas \"Month\" e \"1958\" usando F.col\n",
    "df_select_col = df.select(F.col(\"Month\"), F.col(\"1958\"))\n",
    "display(df_select_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43ddff52-46ab-4c43-9e7c-b3f2214eee8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Equivalente em SQL:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1192a59-f95c-4852-9738-d323c8c3e861",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT Month, `1958` \n",
    "  FROM airtravel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "260b3d77-b5dc-4345-930e-de5720192bc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "###### Sem `F.col` (Referência Direta)\n",
    "\n",
    "Colunas podem ser referenciadas diretamente por nome usando strings, o que é simples e direto para seleções básicas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a915f889-c75e-46ec-b6bf-02aaa5008743",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Selecionar colunas \"Month\" e \"1958\" sem usar F.col, apenas com strings\n",
    "df_select_strings = df.select(\"Month\", \"1958\")\n",
    "display(df_select_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4ac3e23-7615-42d1-8bca-6d585d09f080",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "###### Referenciando Colunas Diretamente no DataFrame\n",
    "\n",
    "Colunas também podem ser acessadas diretamente através do DataFrame, útil em contextos de transformações dentro de expressões mais complexas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9761dc8-a4b9-4c48-b4cc-077a839c6a2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Selecionar colunas diretamente no DataFrame usando acesso direto\n",
    "df_direct = df.select(df.Month, df[\"1958\"])\n",
    "display(df_direct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "859bdf62-ccd8-4b99-ada6-9a7c07c196cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "##### Filtragem de Dados (`filter`)\n",
    "\n",
    "A função `filter` em PySpark permite aplicar condições para selecionar linhas específicas de um DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3436504-22d3-43fd-844c-887fc5a67d66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02f80078-9fdc-47d2-b07b-b3d0cee467b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b32aab96-f486-4051-b330-3d6ec3005106",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filtrar linhas onde o número de passageiros em 1958 é maior que 300 usando F.col\n",
    "df_filter = df.filter(F.col(\"1958\") > 300)\n",
    "display(df_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c4d56807-2091-4832-ad68-cd55ee1fd9bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Equivalente em SQL:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e55651f-b12e-4ef4-9527-f4fa8c866ad8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_filter = spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM airtravel\n",
    "WHERE `1958` > 300\"\"\")\n",
    "display(df_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39962432-c121-48da-bb22-c50db3880a9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM airtravel\n",
    "WHERE `1958` > 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d54876b9-a19e-45af-807c-f8e73154edda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "##### Adicionando ou Modificando Colunas (`withColumn`)\n",
    "\n",
    "O `withColumn` é usado para adicionar novas colunas ou modificar colunas existentes em um DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5e49a1b-72f9-4e3b-bdac-07b872e980e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Adicionar uma nova coluna com incremento de passageiros de 1958 para 1959 usando F.expr\n",
    "df_with_column = df.withColumn(\"Incremento\", F.expr(\"`1959` - `1958`\"))\n",
    "display(df_with_column)\n",
    "\n",
    "df_with_column = df.withColumn(\"Incremento\", F.col(\"1959\") - F.col(\"1958\"))\n",
    "display(df_with_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89cd18d2-b727-410f-ae76-f9bc278c9970",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Equivalente em SQL:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "900f3f04-896e-4214-b058-de3e4798e17c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *, (`1959` - `1958`) AS Incremento\n",
    "FROM airtravel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd985adb-bec9-4d92-ac53-9f5e51c033f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "##### Renomeando Colunas (`withColumnRenamed`)\n",
    "\n",
    "Renomear colunas em PySpark é feito com `withColumnRenamed`, ideal para limpar e padronizar nomes de colunas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f301a117-d136-4e5b-b508-43f096370dc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Renomear a coluna \"1958\" para \"Ano1958\"\n",
    "df_renamed = df.withColumnRenamed(\"1958\", \"Ano1958\")\n",
    "display(df_renamed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c71d1c0a-bd6a-43a2-8bf3-ce426594cefe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Equivalente em SQL:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2be7685d-68ed-4a55-a0a0-63a6d8be329c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT Month, `1958` AS Ano1958, `1959`, `1960`\n",
    "FROM airtravel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98ff2d41-a7a6-4de7-835a-5a17dac5ad54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "##### Removendo Colunas (`drop`)\n",
    "\n",
    "A função `drop` é usada para remover colunas desnecessárias de um DataFrame, simplificando a estrutura dos dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ec24bfc-460a-4a0c-9519-1255d8adcc8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Remover a coluna \"1960\" usando drop\n",
    "df_drop = df.drop(\"1960\")\n",
    "display(df_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6abc1f09-0a2a-4f8f-8c9c-8b40d7e9fe47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Equivalente em SQL:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50f3835e-e3f1-483f-a5d4-8fe9ca5ea867",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT Month, `1958`, `1959`\n",
    "FROM airtravel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e6628dcc-148a-4064-a831-0e5c089c7650",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "##### Removendo Duplicatas (`distinct`)\n",
    "\n",
    "`distinct` remove linhas duplicadas, assegurando a unicidade dos registros no DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f03e1d71-1132-4f57-90df-3021ab1eef30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Remover duplicatas no DataFrame\n",
    "df_distinct = df.distinct()\n",
    "display(df_distinct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e43dec4c-818e-4161-b2a8-6bb3117d9ec3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Equivalente em SQL:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01da0422-b78a-4d7b-b937-1b9ead46cf5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT DISTINCT *\n",
    "FROM airtravel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b3102b3-24b9-417b-97c0-2a2a3bbcc207",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "##### Ordenando Dados (`orderBy`)\n",
    "\n",
    "`orderBy` organiza os dados em ordem específica, essencial para análises que envolvem classificação ou tendências.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a4ec898-de94-44c7-9574-1f295f34340d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ordenar o DataFrame pela coluna \"1958\" em ordem decrescente usando F.col\n",
    "df_order = df.orderBy(F.col(\"1958\").desc())\n",
    "display(df_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b989be8-b941-4a9b-b9a4-5f1ab8621309",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Equivalente em SQL:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ed913ee-1444-4116-8314-de7c96235c00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM airtravel\n",
    "ORDER BY `1958` DESC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c64eac4-8ca8-48a4-98ba-b3a71fd861f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "##### Agregações (`groupBy`)\n",
    "\n",
    "A função `groupBy` agrupa os dados por uma ou mais colunas e permite aplicar funções agregadas como `sum`, `avg`, e `count`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e65614b8-ef2a-4ab9-b42e-c4a457feec4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Agrupar por 'Month' e somar os valores de \"1958\" usando F.sum\n",
    "df_group = (\n",
    "    df\n",
    "        .groupBy(\"Month\")\n",
    "        .agg(\n",
    "            F.sum(\"1958\").alias(\"total_1958\")\n",
    "        )\n",
    ")\n",
    "display(df_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0d181c1-d0ba-4aad-8786-d4dd748b93ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Equivalente em SQL:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "134d2518-c493-4339-9df9-f57214216b07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT Month, SUM(`1958`) AS total_1958\n",
    "FROM airtravel\n",
    "GROUP BY Month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3899962d-c50b-4bd5-96a4-04acd358bdb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "##### Funcões de agrupamento\n",
    "\n",
    "Documentação de referência: [Aggregate Functions](https://spark.apache.org/docs/latest/sql-ref-functions-builtin.html#aggregate-functions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0174d0ce-9974-4b44-b42a-71a9701995a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_agg = (\n",
    "    df\n",
    "    .agg(\n",
    "        F.sum(\"1958\").alias(\"total_1958\"), \n",
    "        F.avg(\"1958\").alias(\"avg_1958\"), \n",
    "        F.mean(\"1958\").alias(\"mean_1958\"), \n",
    "        F.median(\"1958\").alias(\"median_1958\"), \n",
    "        F.count(\"1958\").alias(\"count_1958\"),\n",
    "        F.min(\"1958\").alias(\"min_1958\"),\n",
    "        F.max(\"1958\").alias(\"max_1958\"),\n",
    "    )\n",
    ")\n",
    "display(df_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fbc0997a-fcf2-475a-998a-dc237d181bed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Equivalente em SQL:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abe7002b-8ee9-4df8-8d36-1e16a7cdcc3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT \n",
    "    avg(`1958`) AS avg_1958, \n",
    "    mean(`1958`) AS mean_1958, \n",
    "    median(`1958`) AS median_1958,\n",
    "    sum(`1958`) AS total_1958,\n",
    "    count(`1958`) AS count_1958,\n",
    "    min(`1958`) AS median_1958,\n",
    "    max(`1958`) AS median_1958\n",
    "FROM airtravel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e058b282-a05a-4ecb-9e8c-857d2a06ae55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Resumo das principais funções**\n",
    "Aqui está uma tabela com o resumo das principais funções de agregação que discutimos:\n",
    "\n",
    "| Função                       | Descrição                                             | Fórmula/Definição                                               | Exemplo de Dados   | Resultado         |\n",
    "|------------------------------|-------------------------------------------------------|-----------------------------------------------------------------|--------------------|-------------------|\n",
    "| **`COUNT`**                  | Conta o número total de elementos                     | $$\\text{COUNT} = \\text{Número total de elementos}$$             | [1, 2, 3, 4, 5]    | 5                 |\n",
    "| **`MIN`**                    | Retorna o valor mínimo em um conjunto de dados        | $$\\text{MIN} = \\text{Valor mínimo em um conjunto}$$             | [3, 5, 1, 8, 2]    | 1                 |\n",
    "| **`MAX`**                    | Retorna o valor máximo em um conjunto de dados        | $$\\text{MAX} = \\text{Valor máximo em um conjunto}$$             | [3, 5, 1, 8, 2]    | 8                 |\n",
    "| **`SUM`**                    | Retorna a soma total dos valores                      | $$\\text{SUM} = \\sum_{i=1}^{n} x_i$$                             | [3, 5, 1, 8, 2]    | 19                |\n",
    "| **`AVG`** (Média)            | Retorna a média aritmética dos valores                | $$\\text{AVG} = \\frac{\\sum x_i}{n}$$                             | [1, 2, 3, 4, 5]    | 3                 |\n",
    "| **`MEAN`**                   | Outra denominação para a média aritmética             | Idêntico ao `AVG`                                               | [1, 2, 3, 4, 5]    | 3                 |\n",
    "| **`MEDIAN`**                 | Retorna o valor central em um conjunto ordenado       | Valor do meio em um conjunto ordenado                           | [1, 2, 3, 4, 5]    | 3                 |\n",
    "| **`VAR`** (Variância)        | Mede a dispersão dos dados em relação à média         | $$\\text{VAR} = \\frac{1}{n}\\sum(x_i - \\text{mean})^2$$           | [1, 2, 3, 4, 5]    | 2                 |\n",
    "| **`STDDEV`** (Desvio Padrão) | Mede a dispersão média dos dados                      | $$\\text{STDDEV} = \\sqrt{\\frac{1}{n}\\sum(x_i - \\text{mean})^2}$$ | [1, 2, 3, 4, 5]    | 1.41              |\n",
    "| **`FIRST`**                  | Retorna o primeiro valor de uma coluna                | -                                                               | [1, 2, 3, 4, 5]    | 1                 |\n",
    "| **`LAST`**                   | Retorna o último valor de uma coluna                  | -                                                               | [1, 2, 3, 4, 5]    | 5                 |\n",
    "| **`COLLECT_LIST`**           | Agrupa valores de uma coluna em uma lista             | -                                                               | [1, 2, 3, 4, 5]    | [1, 2, 3, 4, 5]   |\n",
    "| **`COLLECT_SET`**            | Agrupa valores distintos de uma coluna em um conjunto | -                                                               | [1, 2, 2, 4, 5]    | {1, 2, 4, 5}      |\n",
    "| **`PERCENTILE`**             | Retorna o valor de um percentil de uma coluna         | $$\\text{PERCENTILE}(p)$$                                        | [1, 2, 3, 4, 5]    |  Depende de $$p$$ |\n",
    "| **`MODE`**                   | Retorna o valor que ocorre com mais frequência (moda) | -                                                               | [1, 2, 2, 3, 3, 3] | 3                 |\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b06b843-cac0-49e2-9da3-3eb8df311b28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Junções de DataFrames (`join`)\n",
    "\n",
    "Junções em PySpark permitem combinar DataFrames com base em chaves comuns, facilitando a integração de dados de diferentes fontes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4573279e-5508-46c8-b7b8-fe1750fb532f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df2 = df.withColumnRenamed(\"1958\", \"Ano1958\").withColumnRenamed(\"1959\", \"Ano1959\")\n",
    "df_join = df.join(df2, on=\"Month\", how=\"inner\")\n",
    "display(df_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b284752-07fb-404d-abba-0e6993925600",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df2 = df.withColumnRenamed(\"1958\", \"Ano1958\").withColumnRenamed(\"1959\", \"Ano1959\")\n",
    "df_join = df.join(df2, on=[\"Month\"], how=\"inner\") # 2a variacao de como fazer o join\n",
    "display(df_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59ba2279-1f9d-485a-9046-4fae1f3ae6c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df2 = df.withColumnRenamed(\"1958\", \"Ano1958\").withColumnRenamed(\"1959\", \"Ano1959\")\n",
    "df_join = (\n",
    "  df.alias(\"df\")\n",
    "    .join(\n",
    "        df2.alias(\"df2\"), \n",
    "        F.col(\"df.Month\") == F.col(\"df2.Month\"), \n",
    "        how=\"inner\") # 3a variacao de como fazer o join\n",
    ")\n",
    "display(df_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "066a82ae-5789-4216-ac08-c7948e433364",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Equivalente em SQL:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8932b75-7440-42e1-935f-9f54b8384fd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "with airtravel2 as (\n",
    "select \n",
    "    month,\n",
    "    `1958` as ano1958,\n",
    "    `1959` as ano1959\n",
    "from airtravel\n",
    ")\n",
    "select \n",
    "    df.*, \n",
    "    df2.ano1958, \n",
    "    df2.ano1959\n",
    "from airtravel as df\n",
    "    inner join airtravel2 as df2 \n",
    "        on df2.month = df.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "602e8fc5-b1ad-42d6-aec4-8bc8e28aff90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "##### Funções de Janela (Window Functions)\n",
    "\n",
    "Funções de janela são usadas para cálculos que precisam de um contexto mais amplo, como médias móveis ou classificações dentro de grupos.\n",
    "\n",
    "**Preparando os dados**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b2ee690-ddc0-4547-b607-1bc0d9deef3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Criar uma massa de dados\n",
    "data = [\n",
    "    (\"Marketing\", \"Alice\", 5000),\n",
    "    (\"Marketing\", \"Bob\", 6000),\n",
    "    (\"Marketing\", \"Charlie\", 7000),\n",
    "    (\"Sales\", \"Dave\", 4000),\n",
    "    (\"Sales\", \"Eve\", 4500),\n",
    "    (\"Sales\", \"Frank\", 4800),\n",
    "    (\"IT\", \"Grace\", 5500),\n",
    "    (\"IT\", \"Heidi\", 6000)\n",
    "]\n",
    "\n",
    "# Definir o esquema do DataFrame\n",
    "columns = [\"department\", \"employee\", \"salary\"]\n",
    "\n",
    "# Criar o DataFrame\n",
    "employee_df = spark.createDataFrame(data, columns)\n",
    "employee_df.createOrReplaceTempView(\"employee\")\n",
    "\n",
    "# Mostrar os dados iniciais\n",
    "print(\"Dados iniciais:\")\n",
    "display(employee_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12cbf997-213c-477d-929e-defdf5dc0ded",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Aplicando row_number dentro de cada departamento**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f0fc31e-7d48-4a6a-ae2e-55bde168fe0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Definir a janela de partição por departamento\n",
    "windowSpec = Window.partitionBy(\"department\").orderBy(\"salary\")\n",
    "\n",
    "# Aplicar row_number() para numerar as linhas dentro de cada departamento\n",
    "employee_df_with_row_number = employee_df.withColumn(\"row_number\", F.row_number().over(windowSpec))\n",
    "\n",
    "# Mostrar o resultado com row_number\n",
    "print(\"Aplicando row_number dentro de cada departamento:\")\n",
    "display(employee_df_with_row_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ece0df5b-b786-4127-838a-c291c58c2a26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Equivalente em SQL:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b08ed1cf-e0f2-4545-8a4a-cdc028406267",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT\n",
    "    department,\n",
    "    employee,\n",
    "    salary,\n",
    "    ROW_NUMBER() OVER (PARTITION BY department ORDER BY salary) AS row_number\n",
    "FROM employee;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70dadf8c-67ab-4b23-a351-8005564f7f16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Usar a função lead() para capturar o salário da próxima linha dentro da partição\n",
    "employee_df_with_next_salary = employee_df_with_row_number.withColumn(\"next_salary\", F.lead(\"salary\").over(windowSpec))\n",
    "\n",
    "# Mostrar o resultado final com o valor da próxima linha\n",
    "print(\"Mostrando o salário da próxima linha dentro de cada departamento:\")\n",
    "display(employee_df_with_next_salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15893252-ee77-421b-b285-6551d2c403f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Equivalente em SQL:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05b3146d-df8b-449b-a5f0-b33447b5201c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT \n",
    "    department,\n",
    "    employee,\n",
    "    salary,\n",
    "    ROW_NUMBER() OVER (PARTITION BY department ORDER BY salary) AS row_number,\n",
    "    LEAD(salary) OVER (PARTITION BY department ORDER BY salary) AS next_salary\n",
    "FROM employee;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9d7af7c-141c-4910-9f96-cd8febf3d01f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "##### Combinação de DataFrames (`union`)\n",
    "\n",
    "Documentação de referência: https://spark.apache.org/docs/3.5.2/sql-ref-syntax-qry-select-setops.html\n",
    "\n",
    "`union` é usado para combinar DataFrames verticalmente, adicionando registros de um DataFrame ao outro.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cea52102-0fd8-452a-ad0e-91227ecd591b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# União de DataFrame consigo mesmo usando union\n",
    "df_union = df.union(df)\n",
    "display(df_union)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "367dd4c3-fe7b-4464-84d6-b80e5902567e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Equivalente em SQL:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abfe0454-2301-4214-ace3-c02adb83961d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM airtravel\n",
    "UNION ALL\n",
    "SELECT * FROM airtravel;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "044c0357-1352-43c4-8809-cd61c1a57462",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "##### Limitação de Linhas (`limit`)\n",
    "\n",
    "`limit` restringe o DataFrame a um número específico de linhas, útil para inspeções rápidas de dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccbfd895-1b84-4385-80a9-8c8c5387ff40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Limitar o DataFrame para mostrar apenas as 3 primeiras linhas\n",
    "df_limit = df.limit(3)\n",
    "display(df_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "202ef5c3-5593-42d9-82a9-8ee55c9fa9cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Equivalente em SQL:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d02fba63-5d91-4c89-b503-62e490971848",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM airtravel\n",
    "LIMIT 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "57ef8826-1e5c-44ca-91b6-60424159c630",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "##### Amostragem Aleatória (`sample`)\n",
    "\n",
    "A função `sample` cria uma amostra aleatória de linhas do DataFrame, essencial para análises exploratórias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67407049-eacb-43f0-a363-2e8d065630aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Amostra aleatória do DataFrame (50% dos dados) usando sample\n",
    "df_sample = df.sample(0.5)\n",
    "display(df_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81cf689f-298c-4e35-ae84-16cdbcba3aae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Equivalente em SQL:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c0e818a-8f65-454c-b463-efb474d72635",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Nota: SQL padrão não suporta `SAMPLE` diretamente. Em Spark SQL específico:\n",
    "SELECT *\n",
    "FROM airtravel\n",
    "TABLESAMPLE (50 PERCENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e383fc3f-3491-4b69-8d07-ff96f0f427c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Equivalente em SQL:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55331c39-a7f1-4d70-8803-32cd871c0f10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Não há equivalente direto em SQL para reparticionar DataFrames. Esta operação é específica para gerenciamento de desempenho em Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "603a1eee-4002-4fde-9ed8-cf516438e2f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "##### Função explode\n",
    "\n",
    "###### Exemplo 1: Trabalhando com Array\n",
    "\n",
    "- Preparando os dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce6a732d-74a6-4269-8a8a-6e8730bcdbc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Criar um DataFrame com uma coluna de array\n",
    "data = [\n",
    "    (\"John\", [\"Python\", \"Java\", \"C++\"]),\n",
    "    (\"Alice\", [\"Scala\", \"Python\"]),\n",
    "    (\"Bob\", [\"Java\", \"C#\"])\n",
    "]\n",
    "columns = [\"name\", \"languages\"]\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "df.createOrReplaceTempView(\"programadores\")\n",
    "\n",
    "# Mostrar o DataFrame original\n",
    "print(\"DataFrame original:\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f15263e-dbfd-4fa4-b993-31e99f570933",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "- Usando **`F.explode`** para \"explodir\" o array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "644d7737-44b1-4b7d-bca8-cc8467da297b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Explodir a coluna de array \"languages\"\n",
    "df_exploded = df.select(\"name\", F.explode(F.col(\"languages\")).alias(\"language\"))\n",
    "\n",
    "# Mostrar o DataFrame após usar explode\n",
    "print(\"DataFrame após explodir o array:\")\n",
    "display(df_exploded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28bb7575-5ed3-459b-94f7-9b30bea3b798",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Equivalência em SQL **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "736033b4-204a-42f3-a0de-c309181ede64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT \n",
    "  name, \n",
    "  EXPLODE(languages) AS language\n",
    "FROM programadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91e6aa30-cba9-4099-8e88-f938f3f1c941",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "\n",
    "###### Exemplo 2: Trabalhando com JSON\n",
    "\n",
    "- Preparando os dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38bf2fb5-51b4-4b34-b2e2-307894fd2f14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType\n",
    "\n",
    "# Definindo um esquema para o JSON aninhado\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"projects\", ArrayType(\n",
    "        StructType([\n",
    "            StructField(\"project_name\", StringType(), True),\n",
    "            StructField(\"skills\", ArrayType(StringType()), True)\n",
    "        ])\n",
    "    ), True)\n",
    "])\n",
    "\n",
    "# Massa de dados com JSON aninhado\n",
    "data = [\n",
    "    (\"John\", [{\"project_name\": \"AI Project\", \"skills\": [\"Python\", \"TensorFlow\"]},\n",
    "              {\"project_name\": \"Web App\", \"skills\": [\"JavaScript\", \"React\"]}]),\n",
    "    (\"Alice\", [{\"project_name\": \"Data Analysis\", \"skills\": [\"Python\", \"Pandas\"]}])\n",
    "]\n",
    "\n",
    "# Criar DataFrame\n",
    "df = spark.createDataFrame(data, schema)\n",
    "df.createOrReplaceTempView(\"funcionarios\")\n",
    "\n",
    "# Mostrar o DataFrame original com JSON aninhado\n",
    "print(\"DataFrame original com JSON aninhado:\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af7ebd15-f839-4fb8-8d83-af8455646a77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "- Usando **`F.explode`** para \"explodir\" o array de projetos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc768d6c-1044-478d-9de6-863e09eae46c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Explodir o array \"projects\"\n",
    "df_exploded_projects = (\n",
    "    df.select(\n",
    "        \"name\", \n",
    "        F.explode(F.col(\"projects\")).alias(\"project_info\")\n",
    "    )\n",
    ")\n",
    "# Mostrar o DataFrame após explodir o array de projetos\n",
    "print(\"DataFrame após explodir o array de projetos:\")\n",
    "display(df_exploded_projects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b91c8cfd-d635-4a22-a209-45d7fcf4ce0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Equivalência em SQL**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa05c3e0-6172-43ec-a942-1af9aa49541b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Explodir os projetos\n",
    "SELECT name, EXPLODE(projects) AS project_info\n",
    "FROM funcionarios;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56293d26-780b-41c6-986d-bfc4ed4bb82d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "- Explodir o array de habilidades dentro dos projetos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2207daab-a189-4570-b86a-b57bfa0a7aa9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Explodir o array \"skills\" dentro de cada projeto\n",
    "df_exploded_skills = (\n",
    "    df_exploded_projects.select(\n",
    "        \"name\", \n",
    "        \"project_info.project_name\",\n",
    "        F.explode(F.col(\"project_info.skills\")).alias(\"skill\")\n",
    "    )\n",
    ")\n",
    "# Mostrar o DataFrame final com todas as habilidades explodidas\n",
    "print(\"DataFrame após explodir o array de habilidades:\")\n",
    "display(df_exploded_skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e226f1af-7dec-4830-afdf-ae5fe8c7d1f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Equivalência em SQL**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fecde083-9479-4c0c-a5ed-9629063c44c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Explodir as habilidades dentro de cada projeto\n",
    "SELECT name, project_info.project_name, EXPLODE(project_info.skills) AS skill\n",
    "FROM (\n",
    "    SELECT name, EXPLODE(projects) AS project_info\n",
    "    FROM funcionarios\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c19da3e3-8d2f-4337-95d0-0efce7b5c2ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "with estagio01 as (\n",
    "  SELECT \n",
    "    name, \n",
    "    EXPLODE(projects) AS project_info\n",
    "  FROM funcionarios\n",
    ")\n",
    "SELECT \n",
    "  name, \n",
    "  project_info.project_name, \n",
    "  EXPLODE(project_info.skills) AS skill\n",
    "FROM estagio01;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "449179d4-6c06-45b2-9fff-3eadd5db7074",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "`[INFO]: FIM DO NOTEBOOK`"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4198194417610099,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "02.01.manipulacao-de-dados-transformation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
