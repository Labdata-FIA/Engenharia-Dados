# Lab Armazenamento Distribuido


## Disclaimer
> **As configura√ß√µes dos Laborat√≥rios √© puramente para fins de desenvolvimento local e estudos**


## Pr√©-requisitos?
* Docker
* Docker-Compose


Este laborat√≥rio foi criado para praticar, de ponta a ponta, os conceitos principais do Hive. A ideia √© mostrar, na pr√°tica, como usar Hive para consultar dados em HDFS, incluindo cria√ß√£o de bancos, tabelas, inser√ß√µes, particionamento, tabelas externas, uso de m√∫ltiplos arquivos CSV, propriedades, e execu√ß√£o de scripts `.hql`.

## üì¶ Estrutura de diret√≥rios HDFS

A estrutura a ser criada no HDFS ser√° a seguinte:

```

‚îú‚îÄ‚îÄ bronze/
‚îÇ   ‚îî‚îÄ‚îÄ alunos/
    ‚îî‚îÄ‚îÄ produtos/

```

---

* > http://localhost:9864/
* > http://localhost:9870/

```bash
docker container rm $(docker ps -a -q) -f
docker volume prune

docker compose up -d datanode namenode hive metastore minio

docker exec -it namenode bash

```


### üîç Verificar modo seguro (Safe Mode)

```bash
hdfs dfsadmin -safemode get
```

### Se o retorno for `Safe mode is OFF` ent√£o n√£o est√°, pode pular o proximo comando.

### üö´ Sair do modo seguro manualmente

```bash
hdfs dfsadmin -safemode leave

hdfs fsck -delete

exit
```

## üöÄ Comandos iniciais

### Criar diret√≥rios no HDFS

```bash
//Caso esteja o container namenode
exit 

docker exec -it hive bash
hdfs dfs -mkdir -p /bronze/alunos
hdfs dfs -mkdir -p /bronze/produtos/
```
### Deu certo ?
> http://localhost:9870/

> Se Precisar subir muitos arquivo - hdfs dfs -put /tmp/exercicio_vendas/* /user/hive/warehouse/exercicio_vendas/
---

## üìÇ Exerc√≠cios pr√°ticos


### Enviando arquivos `alunos.csv` `produtos.csv` para o HDFS

```bash
hdfs dfs -put /util/alunos.csv /bronze/alunos/
hdfs dfs -put /util/produtos.csv /bronze/produtos/
```

### Visualiza√ß√£o dos dados

```bash
hdfs dfs -ls /bronze/alunos/
hdfs dfs -cat /bronze/produtos/produtos.csv
```


### Conectar no Beeline

```bash
beeline -u jdbc:hive2://localhost:10000
```

> Se pedir login, use qualquer usu√°rio (ex: `hive`) e pressione Enter para senha vazia.


### Conectar pelo Dbeaver
![HFDS](/content/hive-01.png)

![HFDS](/content/hive-02.png)


### Criando o  banco de dados

```sql
CREATE DATABASE IF NOT EXISTS db;

SHOW DATABASES;

DROP DATABASE aula_hive CASCADE;

```
#### CASCADE
* Remove o banco de dados e todas as tabelas dentro dele.
* Tabelas internas: arquivos apagados do HDFS.
* Tabelas externas: arquivos permanecem no HDFS, mas o metadado √© removido.


```sql
CREATE DATABASE IF NOT EXISTS aula_hive;
USE aula_hive;

CREATE TABLE pessoas (
  id INT,
  nome STRING,
  idade INT
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE;

INSERT INTO pessoas VALUES (1, 'Maria', 22);
INSERT INTO pessoas VALUES (2, 'Jo√£o', 25);
INSERT INTO pessoas VALUES (3, 'Ana', 20);

SELECT * FROM pessoas;

show tables;
```

### Local do arquivo
/user/hive/warehouse/<nome_tabela>

|                                  | **Tabela Interna**             | **Tabela Externa**        |
|----------------------------------|--------------------------------|---------------------------|
| **Local dos dados**              | HDFS (gerenciado pelo Hive)    | HDFS (ou outro local), gerenciado pelo usu√°rio |
| **Quem gerencia os dados?**      | Hive                           | Usu√°rio                  |
| **Arquivos apagados ao dropar?** | ‚úÖ Sim                          | ‚ùå N√£o                 |
| **Quando usar?**                 | Quando o Hive controla tudo    | Quando os dados j√° existem ou s√£o compartilhados |


- Tabelas internas s√£o totalmente gerenciadas pelo Hive.  
- Tabelas externas s√≥ armazenam metadados; os arquivos f√≠sicos permanecem ap√≥s o drop.

### Metadados

```sql

DESCRIBE DATABASE aula_hive;
DESCRIBE pessoas;
DESCRIBE FORMATTED pessoas;

```

### Consultando Hcatalog (Conectando ao PostgreSql)

![HFDS](/content/hive-postgres.png)


![HFDS](/content/hive-postgres_01.png)
```sql
select * from public."DBS";

select * from  public."TBLS" where "DB_ID"= <<pegar o id do banco do resulta da query acima>>

select * from "COLUMNS_V2" where "CD_ID" = <<pegar o id da tabela do resultada da query acima>>
```


### Carregando dados do HFDS

```sql

CREATE TABLE alunos (
  id INT,
  nome STRING,
  idade INT
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE;

LOAD DATA INPATH '/bronze/alunos/alunos.csv' into table alunos;

select * from alunos;

```

```sql

CREATE EXTERNAL TABLE IF NOT EXISTS produtos (
  id_produto INT,
  nome_produto STRING,  
  valor_total DOUBLE
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE
LOCATION '/bronze/produtos/'
TBLPROPERTIES ("skip.header.line.count"="1");

```

>Com skip.header.line.count=1, apenas as linhas com dados ser√£o carregadas.
>Por padr√£o, o valor √© 0, ou seja, n√£o ignora nenhuma linha.
>Se o seu arquivo n√£o tiver cabe√ßalho, mantenha 0.

### Em outro terminal

```bash
docker exec -it hive bash
hdfs dfs -put /util/produtos.csv /bronze/produtos/
```

### Volte para terminal que esta o hive ativo 
```sql
select * from produtos;
```

### Criando tabelas de uma query

```sql
create table produto_cafe as select * from produtos where id_produto =  2;
```

### Exemplos de queries Hive

### WHERE
```sql
SELECT * 
FROM alunos 
WHERE idade > 23;
```

### ORDER BY
```sql
SELECT * 
FROM alunos 
ORDER BY idade DESC;
```

### LIMIT
```sql
SELECT * 
FROM alunos 
ORDER BY idade DESC
LIMIT 2;
```

### Agrega√ß√£o (COUNT e AVG)
```sql
SELECT COUNT(*) as total_alunos, AVG(idade) as media_idade
FROM alunos;
```

### GROUP BY
```sql
SELECT idade, COUNT(*) as qtd
FROM alunos
GROUP BY idade;
```

### LIKE
```sql
SELECT * 
FROM alunos
WHERE nome LIKE 'M%';
```

### BETWEEN
```sql
SELECT * 
FROM alunos
WHERE idade BETWEEN 21 AND 25;
```


### JOIN
```sql
SELECT a.nome, c.valor_total
FROM alunos a
JOIN compras c
ON a.id = c.id_cliente;
```


### Salvando resultados de consultas no HDFS
```sql
insert overwrite directory
'/result-alunos/' select * from alunos;

hdfs dfs -ls '/result-alunos/'
```
>Formato: JSON Serializado (padr√£o)

### Salvando resultados de consultas no HDFS, formato Delimitado

```sql
insert overwrite local directory
'/result-alunos-delimited/' row format 
delimited fields terminated by ','
select * from alunos;

hdfs dfs -ls '/result-alunos-delimited/'
```

## Particionamento

### No outro terminal, onde esta ativo o container do Hive.

```bash
hdfs dfs -mkdir -p /bronze/aluno_particionamento/ano=2025/mes=06/dia=01
hdfs dfs -put /util/alunos.csv /bronze/aluno_particionamento/ano=2025/mes=06/dia=01/

```

### Criar tabela particionada
```sql
USE aula_hive;

CREATE EXTERNAL TABLE IF NOT EXISTS aluno_particionamento (
  id INT,
  nome STRING,
  idade INT
)
PARTITIONED BY (ano INT, mes INT, dia INT)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE
LOCATION '/bronze/aluno_particionamento';

```
> [!IMPORTANT]
> No HDFS, as pastas representam as parti√ß√µes: 
> Os nomes das pastas devem ter o mesmo nome das colunas de parti√ß√£o (ano, mes, dia), para o Hive reconhecer.

```sql
MSCK REPAIR TABLE aluno_particionamento;
SELECT * FROM aluno_particionamento;
```
> O comando MSCK REPAIR TABLE nome_tabela; serve para atualizar as informa√ß√µes de parti√ß√µes no metastore do Hive. 



## Exemplo de View no Hive

### O que √© uma View?

Uma view no Hive √© uma defini√ß√£o l√≥gica de uma consulta. Ela n√£o armazena dados f√≠sicos no HDFS, apenas a query fica salva no metastore.

```sql
CREATE VIEW alunos_maiores_23_view AS
SELECT *
FROM alunos
WHERE idade > 23;

SELECT * FROM alunos_maiores_23_view;

SHOW VIEWS;

SHOW TABLES;

SHOW CREATE TABLE alunos_maiores_23_view;

```

### No PostgreSql

```sql
select * from  public."TBLS"
```


### O que acontece internamente?

* N√£o √© criado nenhum arquivo no HDFS.
* O Hive apenas salva o SQL da view no metastore.
* Quando voc√™ faz um SELECT na view, o Hive executa a query original na hora, como se fosse uma query normal.




## Exemplo completo usando ORC

### O que √© ORC?

ORC (Optimized Row Columnar) √© um formato de arquivo colunar otimizado, muito usado no Hive para melhorar compress√£o e performance de leitura.

### Configura√ß√£o recomendada
Antes de criar tabelas ORC, configurar compress√£o (opcional):

```bash
SET hive.exec.compress.output=true;
SET orc.compress=SNAPPY;
```

### Criar tabela ORC
```bash
CREATE TABLE alunos_orc (
  id INT,
  nome STRING,
  idade INT
)
STORED AS ORC;

INSERT INTO alunos_orc SELECT * FROM alunos;

```

### Inserir dados
```bash
INSERT INTO alunos_orc VALUES (1, 'Maria', 22);
INSERT INTO alunos_orc VALUES (2, 'Jo√£o', 25);
INSERT INTO alunos_orc VALUES (3, 'Ana', 20);

SELECT * FROM alunos_orc;

```


### O que acontece no HDFS?

* O Hive cria uma pasta para a tabela, por exemplo: /user/hive/warehouse/alunos_orc.
* Os arquivos dentro dessa pasta s√£o salvos no formato ORC (compactados e colunar).
* Cada arquivo ORC armazena dados em blocos, otimizando leitura e reduzindo espa√ßo em disco.




### Vantagens do ORC

* Melhor compress√£o (at√© 75% menor).
* Leituras mais r√°pidas para consultas anal√≠ticas.
* Suporte nativo a predicate pushdown (filtros mais eficientes).

> Para grandes volumes, use ORC para performance e economia de armazenamento. 

